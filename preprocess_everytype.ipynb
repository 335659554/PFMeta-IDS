{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "fs = ['CAN_ID',\n",
    " 'DATA[1]',\n",
    " 'DATA[0]',\n",
    " 'DATA[4]',\n",
    " 'DATA[2]',\n",
    " 'DATA[5]',\n",
    " 'DATA[3]',\n",
    " 'time_stamp',\n",
    " 'DATA[7]']\n",
    "\n",
    "dos = pd.read_csv('./DoS_dataset.csv',names=['time_stamp','CAN_ID','DLC']+['DATA['+str(i)+']' for i in range(8)]+['Label'])\n",
    "\n",
    "fuzzy = pd.read_csv('./Fuzzy_dataset.csv',names=['time_stamp','CAN_ID','DLC']+['DATA['+str(i)+']' for i in range(8)]+['Label'])\n",
    "\n",
    "gear = pd.read_csv('./gear_dataset.csv',names=['time_stamp','CAN_ID','DLC']+['DATA['+str(i)+']' for i in range(8)]+['Label'])\n",
    "\n",
    "rpm = pd.read_csv('RPM_dataset.csv',names=['time_stamp','CAN_ID','DLC']+['DATA['+str(i)+']' for i in range(8)]+['Label'])\n",
    "# df = pd.concat([dos,fuzzy,gear,rpm],axis=0,ignore_index=True)\n",
    "#\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 缺失值补0\n",
    "def zerofilling(df):\n",
    "    for r in range(len(df.index)):\n",
    "        if df.loc[r,'DLC'] < 8:\n",
    "            for i in range(8):\n",
    "                if df.loc[r,'DATA['+str(i)+']'] == 'R' or df.loc[r,'DATA['+str(i)+']'] == 'T':\n",
    "                    df.loc[r,'Label']=df.loc[r,'DATA['+str(i)+']']\n",
    "                    df.loc[r, 'DATA[' + str(i) + ']'] = '00'\n",
    "                    break\n",
    "\n",
    "    df = df.fillna('00')\n",
    "    return df\n",
    "\n",
    "dos = zerofilling(dos)\n",
    "fuzzy = zerofilling(fuzzy)\n",
    "gear = zerofilling(gear)\n",
    "rpm = zerofilling(rpm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 处理timestamp强关联,顺便对CANID作进制转换\n",
    "\n",
    "def trans_timestamp_CANID(df):\n",
    "    for r in reversed(range(len(df.index))):\n",
    "        if r == 0:\n",
    "            df.iloc[r,0] = 0.0\n",
    "        else:\n",
    "            df.iloc[r,0] = float(df.iloc[r,0]) - float(df.iloc[r-1,0])\n",
    "\n",
    "        df.iloc[r,1] = int(df.iloc[r,1],16)\n",
    "    return df\n",
    "\n",
    "\n",
    "# df.to_csv('normal_run_data.csv')\n",
    "# print(df)\n",
    "\n",
    "dos = trans_timestamp_CANID(dos)\n",
    "fuzzy = trans_timestamp_CANID(fuzzy)\n",
    "gear = trans_timestamp_CANID(gear)\n",
    "rpm = trans_timestamp_CANID(rpm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 对DATAFILED作进制转换\n",
    "\n",
    "def trans_datafield(df):\n",
    "    df.loc[:,['DATA['+str(i)+']' for i in range(8)]] = df.loc[:,['DATA['+str(i)+']' for i in range(8)]].applymap(lambda x:int(x,16))\n",
    "    return df\n",
    "\n",
    "dos = trans_datafield(dos)\n",
    "fuzzy = trans_datafield(fuzzy)\n",
    "gear = trans_datafield(gear)\n",
    "rpm = trans_datafield(rpm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# transform the label to 0 and 1\n",
    "dos.loc[:,'Label']=dos.loc[:,'Label'].apply(lambda x:0.0 if x=='R' else 1.0)\n",
    "fuzzy.loc[:,'Label']=fuzzy.loc[:,'Label'].apply(lambda x:0.0 if x=='R' else 1.0)\n",
    "gear.loc[:,'Label']=gear.loc[:,'Label'].apply(lambda x:0.0 if x=='R' else 1.0)\n",
    "rpm.loc[:,'Label']=rpm.loc[:,'Label'].apply(lambda x:0.0 if x=='R' else 1.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dos = dos.astype(float)\n",
    "fuzzy = fuzzy.astype(float)\n",
    "gear = gear.astype(float)\n",
    "rpm = rpm.astype(float)\n",
    "\n",
    "dos.to_csv('./trans_dos.csv',index=0)\n",
    "fuzzy.to_csv('./trans_fuzzy.csv',index=0)\n",
    "gear.to_csv('./trans_gear.csv',index=0)\n",
    "rpm.to_csv('./trans_rpm.csv',index=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dos = dos[fs+['Label']]\n",
    "fuzzy = fuzzy[fs+['Label']]\n",
    "gear = gear[fs+['Label']]\n",
    "rpm = rpm[fs+['Label']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# normalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "km_mean:time_stamp      0.000638\n",
      "CAN_ID        704.903056\n",
      "DLC             7.936663\n",
      "DATA[0]        58.097140\n",
      "DATA[1]        45.526462\n",
      "DATA[2]        40.036807\n",
      "DATA[3]        77.731593\n",
      "DATA[4]        51.284253\n",
      "DATA[5]        61.157021\n",
      "DATA[6]        26.003214\n",
      "DATA[7]        53.561850\n",
      "dtype: float64,km_std:time_stamp      0.001130\n",
      "CAN_ID        397.875027\n",
      "DLC             0.589138\n",
      "DATA[0]        89.915449\n",
      "DATA[1]        54.446672\n",
      "DATA[2]        58.416384\n",
      "DATA[3]       102.117568\n",
      "DATA[4]        73.203852\n",
      "DATA[5]        77.163061\n",
      "DATA[6]        57.129318\n",
      "DATA[7]        80.002116\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "with open('hy_params.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "km_hy_mean = params['hy_mean']\n",
    "km_hy_std = params['hy_std']\n",
    "print(f'km_mean:{km_hy_mean},km_std:{km_hy_std}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:CAN_ID        704.884227\n",
      "DATA[1]        45.525033\n",
      "DATA[0]        58.042142\n",
      "DATA[4]        51.285084\n",
      "DATA[2]        40.035023\n",
      "DATA[5]        61.143568\n",
      "DATA[3]        77.776993\n",
      "time_stamp      0.001600\n",
      "DATA[7]        53.544871\n",
      "dtype: float64,std:CAN_ID        397.754650\n",
      "DATA[1]        54.458214\n",
      "DATA[0]        89.859080\n",
      "DATA[4]        73.180462\n",
      "DATA[2]        58.375761\n",
      "DATA[5]        77.165713\n",
      "DATA[3]       102.143626\n",
      "time_stamp      2.427758\n",
      "DATA[7]        79.942758\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([dos,fuzzy,gear,rpm],axis=0,ignore_index=True)\n",
    "# saving std and mean in hybrid dataset\n",
    "hy_mean = df.drop('Label',axis=1).mean()\n",
    "hy_std = df.drop('Label',axis=1).std()\n",
    "print(f'mean:{hy_mean},std:{hy_std}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAN_ID        704.903056\n",
      "DATA[1]        45.526462\n",
      "DATA[0]        58.097140\n",
      "DATA[4]        51.284253\n",
      "DATA[2]        40.036807\n",
      "DATA[5]        61.157021\n",
      "DATA[3]        77.731593\n",
      "time_stamp      0.000638\n",
      "DATA[7]        53.561850\n",
      "dtype: float64\n",
      "CAN_ID        397.875027\n",
      "DATA[1]        54.446672\n",
      "DATA[0]        89.915449\n",
      "DATA[4]        73.203852\n",
      "DATA[2]        58.416384\n",
      "DATA[5]        77.163061\n",
      "DATA[3]       102.117568\n",
      "time_stamp      0.001130\n",
      "DATA[7]        80.002116\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(km_hy_mean[fs])\n",
    "print(km_hy_std[fs])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAN_ID       -0.018829\n",
      "DATA[1]      -0.001429\n",
      "DATA[0]      -0.054999\n",
      "DATA[4]       0.000831\n",
      "DATA[2]      -0.001784\n",
      "DATA[5]      -0.013453\n",
      "DATA[3]       0.045400\n",
      "time_stamp    0.000962\n",
      "DATA[7]      -0.016979\n",
      "dtype: float64\n",
      "CAN_ID       -0.120378\n",
      "DATA[1]       0.011542\n",
      "DATA[0]      -0.056369\n",
      "DATA[4]      -0.023390\n",
      "DATA[2]      -0.040623\n",
      "DATA[5]       0.002652\n",
      "DATA[3]       0.026058\n",
      "time_stamp    2.426628\n",
      "DATA[7]      -0.059358\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(hy_mean - km_hy_mean[fs])\n",
    "print(hy_std - km_hy_std[fs])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "def normalize_with_params(df, mean, std):\n",
    "    features = df.drop('Label', axis=1)\n",
    "    standardized_features = (features - mean) / std\n",
    "    # 将标准化后的特征赋值回原 DataFrame，保持 'Label' 列不变\n",
    "    df_standardized = standardized_features.copy()\n",
    "    df_standardized['Label'] = df['Label'].values\n",
    "    return df_standardized\n",
    "\n",
    "def normalize(df):\n",
    "    features = df.drop('Label', axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    df.iloc[:,:-1]=features\n",
    "    return df\n",
    "\n",
    "# n_dos = normalize_with_params(dos, dos.drop('Label',axis=1).mean(), dos.drop('Label',axis=1).std())\n",
    "# n_fuzzy = normalize_with_params(fuzzy, fuzzy.drop('Label',axis=1).mean(), fuzzy.drop('Label',axis=1).mean().std())\n",
    "# n_gear = normalize_with_params(gear, gear.drop('Label',axis=1).mean(), gear.drop('Label',axis=1).mean().std())\n",
    "# n_rpm = normalize_with_params(rpm, rpm.drop('Label',axis=1).mean(), rpm.drop('Label',axis=1).mean().std())\n",
    "# n_hybrid = normalize_with_params(df.copy(), hy_mean, hy_std)\n",
    "\n",
    "n_dos = normalize(dos.copy())\n",
    "n_fuzzy = normalize(fuzzy.copy())\n",
    "n_gear = normalize(gear.copy())\n",
    "n_rpm = normalize(rpm.copy())\n",
    "\n",
    "\n",
    "n_dos.to_csv('./norm_dos.csv',index=0)\n",
    "n_fuzzy.to_csv('./norm_fuzzy.csv',index=0)\n",
    "n_gear.to_csv('./norm_gear.csv',index=0)\n",
    "n_rpm.to_csv('./norm_rpm.csv',index=0)\n",
    "# n_hybrid.to_csv('./norm_hybrid.csv',index=0)\n",
    "# features = df.drop('Label',axis=1)\n",
    "# scaler = StandardScaler()\n",
    "# features = scaler.fit_transform(features)\n",
    "# df.iloc[:,:-1]=features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征工程(IG-KPCA)\n",
    "## IG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Read the sampled dataset\n",
    "df=pd.read_csv('./norm_hybrid.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "X = df.drop(['Label'],axis=1).values\n",
    "y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "importances = mutual_info_classif(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "features = df.columns[df.columns!='Label']\n",
    "f_list = sorted(zip(importances, features), reverse=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "Sum = 0\n",
    "for i in range(0, len(f_list)):\n",
    "    Sum = Sum + f_list[i][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "f_list2 = sorted(zip(importances/Sum, features), reverse=True)\n",
    "Sum2 = 0\n",
    "fs = []\n",
    "for i in range(0, len(f_list2)):\n",
    "    Sum2 = Sum2 + f_list2[i][0]\n",
    "    fs.append(f_list2[i][1])\n",
    "    if Sum2>=0.9:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['CAN_ID',\n 'DATA[1]',\n 'DATA[0]',\n 'DATA[4]',\n 'DATA[2]',\n 'DATA[5]',\n 'DATA[3]',\n 'time_stamp',\n 'DATA[7]']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "         CAN_ID   DATA[1]   DATA[0]   DATA[4]   DATA[2]   DATA[5]   DATA[3]  \\\n0     -0.967397 -0.836166 -0.646131 -0.482000 -0.685369 -0.287145 -0.761197   \n1     -0.967397 -0.836166 -0.646131 -0.673247 -0.685369 -0.377862 -0.761197   \n2     -0.967397 -0.836166 -0.646131 -0.482000 -0.685369 -0.131631 -0.761197   \n3     -0.967397 -0.836166 -0.646131 -0.673247 -0.685369 -0.377862 -0.761197   \n4     -0.967397 -0.836166 -0.646131 -0.482000 -0.685369 -0.131631 -0.761197   \n...         ...       ...       ...       ...       ...       ...       ...   \n66260 -0.967397 -0.836166 -0.646131 -0.263432 -0.685369 -0.766649 -0.761197   \n66261 -0.967397 -0.836166 -0.646131 -0.236111 -0.685369 -0.688892 -0.761197   \n66262 -0.967397 -0.836166 -0.646131 -0.290753 -0.685369 -0.624094 -0.761197   \n66263 -0.967397 -0.836166 -0.646131 -0.645926 -0.685369 -0.792569 -0.761197   \n66264 -0.967397 -0.836166 -0.646131 -0.290753 -0.685369 -0.624094 -0.761197   \n\n       time_stamp   DATA[7]  \n0       -0.340333  0.730458  \n1       -0.350041  0.855454  \n2       -0.352785  0.792956  \n3       -0.350041  0.855454  \n4       -0.350885  0.792956  \n...           ...       ...  \n66260   -0.350041  0.280469  \n66261   -0.348142  0.155473  \n66262   -0.350041  0.067975  \n66263   -0.348986  0.180472  \n66264   -0.343921  0.317968  \n\n[66265 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAN_ID</th>\n      <th>DATA[1]</th>\n      <th>DATA[0]</th>\n      <th>DATA[4]</th>\n      <th>DATA[2]</th>\n      <th>DATA[5]</th>\n      <th>DATA[3]</th>\n      <th>time_stamp</th>\n      <th>DATA[7]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.482000</td>\n      <td>-0.685369</td>\n      <td>-0.287145</td>\n      <td>-0.761197</td>\n      <td>-0.340333</td>\n      <td>0.730458</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.673247</td>\n      <td>-0.685369</td>\n      <td>-0.377862</td>\n      <td>-0.761197</td>\n      <td>-0.350041</td>\n      <td>0.855454</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.482000</td>\n      <td>-0.685369</td>\n      <td>-0.131631</td>\n      <td>-0.761197</td>\n      <td>-0.352785</td>\n      <td>0.792956</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.673247</td>\n      <td>-0.685369</td>\n      <td>-0.377862</td>\n      <td>-0.761197</td>\n      <td>-0.350041</td>\n      <td>0.855454</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.482000</td>\n      <td>-0.685369</td>\n      <td>-0.131631</td>\n      <td>-0.761197</td>\n      <td>-0.350885</td>\n      <td>0.792956</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66260</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.263432</td>\n      <td>-0.685369</td>\n      <td>-0.766649</td>\n      <td>-0.761197</td>\n      <td>-0.350041</td>\n      <td>0.280469</td>\n    </tr>\n    <tr>\n      <th>66261</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.236111</td>\n      <td>-0.685369</td>\n      <td>-0.688892</td>\n      <td>-0.761197</td>\n      <td>-0.348142</td>\n      <td>0.155473</td>\n    </tr>\n    <tr>\n      <th>66262</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.290753</td>\n      <td>-0.685369</td>\n      <td>-0.624094</td>\n      <td>-0.761197</td>\n      <td>-0.350041</td>\n      <td>0.067975</td>\n    </tr>\n    <tr>\n      <th>66263</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.645926</td>\n      <td>-0.685369</td>\n      <td>-0.792569</td>\n      <td>-0.761197</td>\n      <td>-0.348986</td>\n      <td>0.180472</td>\n    </tr>\n    <tr>\n      <th>66264</th>\n      <td>-0.967397</td>\n      <td>-0.836166</td>\n      <td>-0.646131</td>\n      <td>-0.290753</td>\n      <td>-0.685369</td>\n      <td>-0.624094</td>\n      <td>-0.761197</td>\n      <td>-0.343921</td>\n      <td>0.317968</td>\n    </tr>\n  </tbody>\n</table>\n<p>66265 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[fs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(66265, 9)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs = df[fs].values\n",
    "X_fs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KPCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components = 6, kernel = 'rbf')\n",
    "kpca.fit(X_fs, y)\n",
    "X_kpca = kpca.transform(X_fs)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# kpca = PCA(n_components = 10)\n",
    "# kpca.fit(X_fss, y)\n",
    "# X_kpca = kpca.transform(X_fss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.45932435, -0.23899496, -0.3236166 , -0.1826117 ,  0.07365631,\n         0.01676231],\n       [ 0.45292158, -0.24986233, -0.33133074, -0.20045482,  0.07159851,\n         0.04994654],\n       [ 0.4317891 , -0.25179356, -0.33296943, -0.17421079,  0.06777208,\n         0.02246888],\n       ...,\n       [ 0.55542132, -0.16324918, -0.22090514, -0.12828752,  0.10282733,\n        -0.0976589 ],\n       [ 0.57336771, -0.18455929, -0.2243492 , -0.14199624,  0.09821739,\n        -0.05751834],\n       [ 0.52949268, -0.17840469, -0.25932368, -0.1643438 ,  0.09707702,\n        -0.05451208]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kpca"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(66265, 6)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kpca.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "['kpca_model.pkl']"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(kpca, \"kpca_model.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# saving dataset after feature engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "fs = ['CAN_ID',\n",
    " 'DATA[1]',\n",
    " 'DATA[0]',\n",
    " 'DATA[4]',\n",
    " 'DATA[2]',\n",
    " 'DATA[5]',\n",
    " 'DATA[3]',\n",
    " 'time_stamp',\n",
    " 'DATA[7]']\n",
    "column = fs+['Label']\n",
    "\n",
    "n_dos = pd.read_csv('./norm_dos.csv',usecols=column)\n",
    "n_fuzzy = pd.read_csv('./norm_fuzzy.csv',usecols=column)\n",
    "n_gear = pd.read_csv('./norm_gear.csv',usecols=column)\n",
    "n_rpm = pd.read_csv('./norm_rpm.csv',usecols=column)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "n_df = pd.concat([n_dos,n_fuzzy,n_gear,n_rpm],axis=0,ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# using kpca model to transform the data\n",
    "kpca = joblib.load(\"kpca_model.pkl\")\n",
    "X_dos = n_dos[fs].values\n",
    "X_fuzzy = n_fuzzy[fs].values\n",
    "X_gear = n_gear[fs].values\n",
    "X_rpm = n_rpm[fs].values\n",
    "X_df = n_df[fs].values\n",
    "\n",
    "# def kpca_transform_in_batches(kpca, data, batch_size=100000):\n",
    "#     \"\"\"\n",
    "#     使用批量处理对数据进行 KPCA 变换。\n",
    "#     \"\"\"\n",
    "#     transformed_batches = []\n",
    "#     for i in range(0, data.shape[0], batch_size):\n",
    "#         batch = data[i:i + batch_size]\n",
    "#         transformed_batch = kpca.transform(batch)\n",
    "#         transformed_batches.append(transformed_batch)\n",
    "#     return np.vstack(transformed_batches)\n",
    "\n",
    "X_dos_kpca = kpca.transform(X_dos)\n",
    "X_fuzzy_kpca = kpca.transform(X_fuzzy)\n",
    "X_gear_kpca = kpca.transform(X_gear)\n",
    "X_rpm_kpca = kpca.transform(X_rpm)\n",
    "X_df_kpca = kpca.transform(X_df)\n",
    "\n",
    "\n",
    "# saving the preprocessed dataset\n",
    "def save_kpca_transformed_data(X_kpca, df, filename):\n",
    "    # Convert the KPCA data to a DataFrame\n",
    "    kpca_df = pd.DataFrame(X_kpca)\n",
    "    # Add the 'Label' column back from the original DataFrame\n",
    "    kpca_df['Label'] = df['Label'].values\n",
    "    # Save the DataFrame to a CSV file\n",
    "    kpca_df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "save_kpca_transformed_data(X_dos_kpca, n_dos, 'dos_preprocessed.csv')\n",
    "save_kpca_transformed_data(X_fuzzy_kpca, n_fuzzy, 'fuzzy_preprocessed.csv')\n",
    "save_kpca_transformed_data(X_gear_kpca, n_gear, 'gear_preprocessed.csv')\n",
    "save_kpca_transformed_data(X_rpm_kpca, n_rpm, 'rpm_preprocessed.csv')\n",
    "save_kpca_transformed_data(X_df_kpca, n_df, 'hybrid_preprocessed.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(n_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
